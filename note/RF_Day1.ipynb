{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RF_Day1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkB/baby-steps-of-rl-ja/blob/master/note/RF_Day1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4z47Jl5vgW4F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "\n",
        "class State():\n",
        "  def __init__(self, row=-1, column=-1):\n",
        "    self.row = row\n",
        "    self.column = column\n",
        "    \n",
        "  def __repr__(self):\n",
        "    return \"<State: [{},{}]>\".format(self.row, self.column)\n",
        "  \n",
        "  def clone(self):\n",
        "    return State(self.row, self.column)\n",
        "  \n",
        "  def __hash__(self):\n",
        "    return hash((self.row, self.column))\n",
        "  \n",
        "  def __eq__(self, other):\n",
        "    return self.row == other.row and self.column == other.column\n",
        "  \n",
        "class Action(Enum):\n",
        "  UP = 1\n",
        "  DOWN = -1\n",
        "  LEFT = 2\n",
        "  RIGHT = -2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hnLJ8z0Zliq2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "class Environment():\n",
        "  \n",
        "  def __init__(self, grid, move_prob=0.8):\n",
        "    # grid is 2d-array. Its vallues are treated as an attribute.\n",
        "    # Kinds of attribute is following.\n",
        "    # 0: ordinary cell\n",
        "    # -1: damage cell (game end)\n",
        "    # 1: reward cell (game end)\n",
        "    # 9: block cell (can't locate agent)\n",
        "    self.grid = grid\n",
        "    self.agent_state = State()\n",
        "    \n",
        "    # Default reward is minus. Just like a position swap\n",
        "    # It means the agent has to reach the goal fast!\n",
        "    self.default_reward = -0.04\n",
        "    \n",
        "    # Agent can move to a selected direction in move_prob.\n",
        "    self.move_prob = move_prob\n",
        "    self.reset()\n",
        "  \n",
        "  @property\n",
        "  def row_length(self):\n",
        "    return len(self.grid)\n",
        "  \n",
        "  @property\n",
        "  def column_length(self):\n",
        "    return len(self.grid[0])\n",
        "  \n",
        "  @property\n",
        "  def actions(self):\n",
        "    return [Action.UP, Action.DOWN, Action.LEFT, Action.RIGHT]\n",
        "  \n",
        "  @property\n",
        "  def states(self):\n",
        "    states = []\n",
        "    for row in range(self.row_length):\n",
        "      # Block cells are not included to the state\n",
        "      if self.grid[row][column] != 9:\n",
        "        states.append(State(row, column))\n",
        "    return states\n",
        "  \n",
        "  def transit_func(self, state, action):\n",
        "    transition_probs = {}\n",
        "    if not self.can_action_at(state):\n",
        "      # Already on the terminal cell.\n",
        "      return transition_probs\n",
        "    \n",
        "    opposite_direction = Action(action.value * -1)\n",
        "    \n",
        "    for a in self.actions:\n",
        "      prob = 0\n",
        "      if a == action:\n",
        "        prob = self.move_prob\n",
        "      elif a != opposite_direction:\n",
        "        prob = (1 - self.move_prob) / 2\n",
        "      \n",
        "      next_state = self._move(state, a)\n",
        "      if next_state not in transition_probs:\n",
        "        transition_probs[next_state] = prob\n",
        "      else:\n",
        "        transition_probs[next_state] += prob\n",
        "        \n",
        "    return transition_probs\n",
        "  \n",
        "  def can_action_at(self, state):\n",
        "    if self.grid[state.row][state.column] == 0:\n",
        "      return True\n",
        "    else:\n",
        "      return False\n",
        "    \n",
        "  def _move(self, state, action):\n",
        "    if not self.can_action_at(state):\n",
        "      raise Exception(\"Can't move from here!\")\n",
        "      \n",
        "    next_state = state.clone()\n",
        "    \n",
        "    # Execute an action(move).\n",
        "    if action == Action.UP:\n",
        "      next_state.row -= 1\n",
        "    elif action == Action.DOWN:\n",
        "      next_state.row += 1\n",
        "    elif action == Action.LEFT:\n",
        "      next_state.column -= 1\n",
        "    elif action == Action.RIGHT:\n",
        "      next_state.column += 1\n",
        "    \n",
        "    # Check whether a state is out of the grid.\n",
        "    if not (0 <= next_state.row < self.row_length):\n",
        "      next_state = state\n",
        "    if not (0 <= next_state.column < self.column_length):\n",
        "      next_state = state\n",
        "    \n",
        "    # Check whether the agent bumped a block cell.\n",
        "    if self.grid[next_state.row][next_state.column] == 9:\n",
        "      next_state = state\n",
        "    \n",
        "    return next_state\n",
        "  \n",
        "  def reward_func(self, state):\n",
        "    reward = self.default_reward\n",
        "    done = False\n",
        "    \n",
        "    # Check an attribute of next state.\n",
        "    attribute = self.grid[state.row][state.column]\n",
        "    if attribute == 1:\n",
        "      # Get reward! and the game ends.\n",
        "      reward = 1\n",
        "      done = True\n",
        "    elif attribute == -1:\n",
        "      # Go damage! and the game ends.\n",
        "      reward = -1\n",
        "      done = True\n",
        "    \n",
        "    return reward, done\n",
        "  \n",
        "  def reset(self):\n",
        "    # Locate the agent at lower left corner.\n",
        "    self.agent_state = State(self.row_length - 1, 0)\n",
        "    return self.agent_state\n",
        "  \n",
        "  def step(self, action):\n",
        "    next_state, reward, done = self.transit(self.agent_state, action)\n",
        "    if next_state is not None:\n",
        "      self.agent_state = next_state\n",
        "      \n",
        "      return next_state, reward, done\n",
        "    \n",
        "  def transit(self, state, action):\n",
        "    transition_probs = self.transit_func(state, action)\n",
        "    if len(transition_probs) == 0:\n",
        "      return None, None, True\n",
        "    \n",
        "    next_states = []\n",
        "    probs = []\n",
        "    for s in transition_probs:\n",
        "      next_states.append(s)\n",
        "      probs.append(transition_probs[s])\n",
        "      \n",
        "    next_state = np.random.choice(next_states, p=probs)\n",
        "    reward, done = self.reward_func(next_state)\n",
        "    return next_state, reward, done"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f9FFD69jd60I",
        "colab_type": "code",
        "outputId": "5771b6e9-2eb7-46ce-b034-2adeeb28aeb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "  \n",
        "  def __init__(self, env):\n",
        "    self.actions = env.actions\n",
        "    \n",
        "  def policy(self, state):\n",
        "    return random.choice(self.actions)\n",
        "  \n",
        "def main():\n",
        "  # Make grid environment.\n",
        "  grid = [\n",
        "      [0, 0, 0, 1],\n",
        "      \n",
        "      [0, 9, 0, -1],\n",
        "      [0, 0, 0, 0]\n",
        "  ]\n",
        "  env = Environment(grid)\n",
        "  agent = Agent(env)\n",
        "  \n",
        "  # Try 10 gmae.\n",
        "  for i in range(10):\n",
        "    # Initialize position of agent.\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    \n",
        "  while not done:\n",
        "    action = agent.policy(state)\n",
        "    next_state, reward, done = env.step(action)\n",
        "    total_reward += reward\n",
        "    state = next_state\n",
        " \n",
        "  print(\"Episode {}: Agent gets {} reward.\".format(i, total_reward))\n",
        "  \n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 9: Agent gets -4.120000000000002 reward.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5tWFyX_ag4iN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}